\chapter{Introduction}

\section{Motivation}
\label{sec:motivation}
According to the World Health Organization (WHO)\footnote{\href{https://www.who.int/news-room/fact-sheets/detail/dementia}{https://www.who.int/news-room/fact-sheets/detail/dementia}}, there are currently around 50 million people suffering from dementia around the word. Despite the already high number of cases and an expectation of 152 million patients by 2050, there is, as of today, no treatment to cure the disease or slow its progression down. However, the quality of life of the patients can be improved when the disease is detected in an early stage. There is therefore a need to build tools that can predict whether a person has the disease or not. Additionally, there is currently no clear understanding of the causes of dementia. Overall  there is a need for a better understanding of the disease.

The recent improvements on the machine learning models and the overall better explainability of their outputs motivates their application to the field of dementia detection.

\section{Problem Statement}
\label{sec:problem_statement}
This thesis aims at provides a machine learning model to automatically detect dementia. The outcome model has the constrain of having reasonable performances in terms of the different losses and metrics defined in section~\ref{sec:losses_metrics} and must be able to explain its predictions.

In our approach, we chose to work with a three-dimensional scan of the brain as input. Namely the raw T1-weighted Magnetic Resonance Images (MRI) of the patient brain. This data is a scan that encodes the anatomy of the brain. 

Our final goal is in a first phase to feed these MRI to the Convolutional Neural Network defined in section~\ref{sec:standard_cnn} in order to obtain a prediction. In a second phase, we explain the previously obtained prediction using the fullgrad algorithm explains in section~\ref{sec:fullgrad}. Finally, the outcome of the two previous phases are visualized using the brain viewer from annex~\ref{chap:brainviewer}. This brain viewer can be used by a clinician to see the original individual scan of the brain, the attention map and the predicted diagnostic.



\section{Research Question & Contributions}
This thesis tackles the following questions:
\begin{itemize}
    \item How can raw MRI scans be used as input to a deep learning model to predict dementia?
    \item Which information does a deep learning model use in order to make its prediction? 
\end{itemize}

In order to answer these questions, the thesis provides the following contribution
\begin{itemize}
    \item We present a prepocessing pipeline that prepares the MRI brain scans for a deep learning model.
    \item We introduce a deep learning model that predicts if a brain scans presents dementia.
    \item We further present a model that visually shows the region of the brain the model used in order to give its prediction
    \item We develop a brain viewer tool that any non-machine learning expert can use to analyze the output and the explanation of the model.
\end{itemize}



\section{Thesis Structure}
\label{sec:structure}
This thesis starts with chapter~\ref{chap:background} which quickly introduces the reader to the dementia diseases in section \ref{sec:medical_background} before listing the different machine learning blocks that will be used during the entire work. This chapter end itself by describing, in section~\ref{sec:model_explaination}, the different techniques used to gain a better understanding of the model's outputs. The following chapter~\ref{chap:data} describes the type of data used and how it has been preporcessed for the models. The thesis continues with chapter~\ref{chap:models}, which presents the different models and their architecture. 
In chapter~\ref{chap:experiments} we briefly explain how the models were trained and the performances obtained from them. This chapter ends by showing the results on models explainability.

Finally, in the last chapter~\ref{chap:conculusion} we conclude the thesis and propose some future work that could be done to improve either the performance or the explanabilty of the models.
